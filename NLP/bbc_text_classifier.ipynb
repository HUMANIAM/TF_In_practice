{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences: 2225\n",
      "labels: 2225\n",
      "Sentence0 : tv future hands viewers home theatre systems plasma high-definition tvs digital video recorders moving living room way people watch tv will radically different \n",
      "lable0 : tech\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/bbc-text.csv\"\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "labels, sentences = [], []\n",
    "headlines = True\n",
    "\n",
    "with open(data_path, \"r\") as csv_file:\n",
    "    for line in csv_file:\n",
    "        if headlines : headlines = False; continue\n",
    "        \n",
    "        label, sentence = line.split(',')\n",
    "        labels.append(label)\n",
    "        for sw in stopwords:\n",
    "            sentence = sentence.replace(' '+sw+' ', ' ').replace('  ', ' ')\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    sentences = np.asarray(sentences)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "print(f\"sentences: {len(sentences)}\")\n",
    "print(f\"labels: {len(labels)}\")\n",
    "print(f\"Sentence0 : {sentences[0][:160]}\")\n",
    "print(f\"lable0 : {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameters\n",
    "vocab_sz = 10000 \n",
    "max_length = 160\n",
    "embedding  = 16\n",
    "oov_tok    = '<oov>'\n",
    "trunc_type = 'post'\n",
    "pad_type   = 'post'\n",
    "num_epochs = 10\n",
    "categories_length = len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_portion = 0.8\n",
    "train_sz = int(training_portion*len(sentences)) \n",
    "\n",
    "train_sentences = sentences[:train_sz] \n",
    "train_labels = labels[:train_sz]\n",
    "val_sentences = sentences[train_sz:]\n",
    "val_labels = labels[train_sz:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n",
      "160\n",
      "200\n",
      "160\n",
      "192\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "# tokenize and padding the training and validation data.\n",
    "tokenizer = Tokenizer(num_words=vocab_sz, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
    "\n",
    "train_padded = np.asarray(train_padded)\n",
    "val_padded = np.asarray(val_padded)\n",
    "\n",
    "print(len(train_sequences[0]))\n",
    "print(len(train_padded[0]))\n",
    "\n",
    "print(len(train_sequences[1]))\n",
    "print(len(train_padded[1]))\n",
    "\n",
    "print(len(train_sequences[10]))\n",
    "print(len(train_padded[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "[2]\n",
      "[1]\n",
      "(1780, 1)\n",
      "[5]\n",
      "[4]\n",
      "[3]\n",
      "(445, 1)\n"
     ]
    }
   ],
   "source": [
    "# tokenize and padding labels\n",
    "\n",
    "labels_tokenizer = Tokenizer(num_words=categories_length+1)\n",
    "labels_tokenizer.fit_on_texts(labels)\n",
    "\n",
    "train_labels_seq = labels_tokenizer.texts_to_sequences(train_labels)\n",
    "val_labels_seq = labels_tokenizer.texts_to_sequences(val_labels)\n",
    "\n",
    "train_labels_seq = np.asarray(train_labels_seq)\n",
    "val_labels_seq = np.asarray(val_labels_seq)\n",
    "\n",
    "print(train_labels_seq[0])\n",
    "print(train_labels_seq[1])\n",
    "print(train_labels_seq[2])\n",
    "print(train_labels_seq.shape)\n",
    "\n",
    "print(val_labels_seq[0])\n",
    "print(val_labels_seq[1])\n",
    "print(val_labels_seq[2])\n",
    "print(val_labels_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define -> compile -> fit your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 160, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 160,742\n",
      "Trainable params: 160,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_sz, embedding, input_length=max_length),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(categories_length+1, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model with adam optimer and categorical crossentropy and accuracey metric\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# get summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9573\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9618\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9618\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9640\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9663\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9640\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(train_padded, train_labels_seq, \n",
    "          validation_data=(val_padded, val_labels_seq), \n",
    "          epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize losses and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string], color='b')\n",
    "    plt.plot(history.history[\"val_\"+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "  \n",
    "    \n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode from words IDs to words text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv future hands viewers home theatre systems plasma high definition tvs digital video recorders moving living room way people watch tv will radically different five years time according expert panel gathered annual consumer electronics show las vegas discuss new technologies will impact one favourite <oov> us leading trend programmes content will delivered viewers via home networks cable satellite telecoms companies broadband service providers front rooms portable devices one talked about technologies ces digital personal video recorders dvr pvr set top boxes like us s tivo uk s sky system allow people record store play pause forward wind tv programmes want essentially technology allows much personalised tv also built in high definition tv sets big business japan us slower take off europe lack high definition programming not can people forward wind adverts can also forget abiding network channel schedules putting together a la <oov> entertainment us networks cable satellite companies worried means terms advertising revenues well brand identity viewer loyalty channels\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(v, k)for (k, v) in word_index.items()])\n",
    "\n",
    "def decode_sentence(txt):\n",
    "    return ' '.join([reverse_index.get(w, '?') for w in txt])\n",
    "\n",
    "print(decode_sentence(train_padded[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save word embeddingVectors as tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# get the embedding verctor of words which is the first layer in the model.\n",
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(embeddings.shape)\n",
    "\n",
    "import io\n",
    "out_v = io.open(\"vecs.tsv\", \"w\", encoding='utf-8');\n",
    "out_m = io.open(\"meta.tsv\", \"w\", encoding='utf-8')\n",
    "\n",
    "for i in range(1,vocab_sz):\n",
    "    wrd = reverse_word_index[i]\n",
    "    out_m.write(wrd+\"\\n\")\n",
    "    out_v.write( '\\t'.join([ str(v) for v in embeddings[i]]) + '\\n')\n",
    "    \n",
    "out_m.close()\n",
    "out_v.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model as tfsavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/bbc_text_learning_embedding_vectors/bbc_text_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n",
      "sentence: tv future hands viewers home theatre systems plasma high-definition tvs digital video recorders moving living room way people watch tv will radically different \n",
      "actual label: tech\n",
      "predicted label: tech\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"granny starting to fear spiders in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
    "print(labels[np.argmax(model.predict(padded)[1])])\n",
    "\n",
    "print(f\"sentence: {sentences[0][:max_length]}\")\n",
    "print(f\"actual label: {labels[0]}\")\n",
    "\n",
    "predicted_label = labels[np.argmax(model.predict([train_padded[0]]))]\n",
    "print(f\"predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
