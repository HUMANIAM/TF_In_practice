{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cats And Dogs Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mTRAINING DATA\u001b[0m\n",
      "Cats: 1000\n",
      "Dats: 1000\n",
      "Cat Image Shape: (374, 500, 3)\n",
      "Dog Image Shape: (500, 332, 3)\n",
      "\u001b[4m\n",
      "\n",
      "Testing DATA\u001b[0m\n",
      "Cats: 500\n",
      "Dats: 500\n",
      "Cat Image Shape: (499, 459, 3)\n",
      "Dog Image Shape: (339, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "data_path = \"data/dogs_cats\"\n",
    "train_path = \"data/dogs_cats/train\"\n",
    "validation_path = \"data/dogs_cats/validation\"\n",
    "\n",
    "print(\"\\033[4mTRAINING DATA\\033[0m\")\n",
    "train_cats_names = os.listdir(os.path.join(train_path, \"cats\"))\n",
    "train_dogs_names = os.listdir(os.path.join(train_path, \"dogs\"))\n",
    "\n",
    "print(\"Cats: {}\".format(len(train_cats_names)))\n",
    "print(\"Dats: {}\".format(len(train_dogs_names)))\n",
    "\n",
    "cat_img = mpimg.imread(os.path.join(train_path, \"cats\", train_cats_names[0]))\n",
    "dog_img = mpimg.imread(os.path.join(train_path, \"dogs\", train_dogs_names[0]))\n",
    "print(f\"Cat Image Shape: {cat_img.shape}\")\n",
    "print(f\"Dog Image Shape: {dog_img.shape}\")\n",
    "\n",
    "## Validation Data\n",
    "print(\"\\033[4m\\n\\nTesting DATA\\033[0m\")\n",
    "val_cats_names = os.listdir(os.path.join(validation_path, \"cats\"))\n",
    "val_dogs_names = os.listdir(os.path.join(validation_path, \"dogs\"))\n",
    "\n",
    "print(\"Cats: {}\".format(len(val_cats_names)))\n",
    "print(\"Dats: {}\".format(len(val_dogs_names)))\n",
    "\n",
    "cat_img = mpimg.imread(os.path.join(validation_path, \"cats\", val_cats_names[0]))\n",
    "dog_img = mpimg.imread(os.path.join(validation_path, \"dogs\", val_dogs_names[0]))\n",
    "print(f\"Cat Image Shape: {cat_img.shape}\")\n",
    "print(f\"Dog Image Shape: {dog_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data\n",
    "pic_index = 0\n",
    "# set the figure size where every image will occupies nrows*ncols inches.\n",
    "def show_imgs(dir_path, cats_names, dogs_names, data_class=\"Train\", fid=1, nrows=1, ncols=4):\n",
    "    global pic_index\n",
    "    plt.figure(fid)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "    # get the (ncols*nrows)/2 horses names and (ncols*nrows)/2 human names.\n",
    "    n = int((ncols*nrows)/2)\n",
    "    pic_index += n\n",
    "    cats = [ os.path.join(dir_path, \"cats\", c) \n",
    "             for c in cats_names[pic_index - n:pic_index] \n",
    "           ]\n",
    "\n",
    "    dogs = [ os.path.join(dir_path, \"dogs\", d) \n",
    "             for d in dogs_names[pic_index-n:pic_index] \n",
    "           ]\n",
    "    for img_i, img_path in enumerate(cats+dogs):\n",
    "        sp = plt.subplot(1, 4, img_i + 1)\n",
    "        sp.set_title(data_class)\n",
    "        sp.axis('Off')\n",
    "        img = mpimg.imread(img_path)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs(train_path, train_cats_names, train_dogs_names)\n",
    "show_imgs(validation_path, val_cats_names, val_dogs_names, \"Testing\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Constants\n",
    "BATCH_SIZE = 20\n",
    "TARGET_SIZE = (150, 150)\n",
    "CLASS_MODE = 'binary'\n",
    "EPOCHS = 10\n",
    "WIDTH, HEIGHT, CHANNELS = cat_img.shape\n",
    "TRAIN_DATA_SIZE = len(train_cats_names) + len(train_dogs_names)\n",
    "VAL_DATA_SIZE = len(val_cats_names) + len(val_dogs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "# those operations will be done using the imageGenerator class 'normalization', `reshaping`, 'etc'\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_datagen       = ImageDataGenerator( rescale = 1.0/255. )\n",
    "train_generator = train_datagen.flow_from_directory(train_path,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=CLASS_MODE,\n",
    "                                                    target_size=TARGET_SIZE)\n",
    "\n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_path,\n",
    "                                                         batch_size  =BATCH_SIZE,\n",
    "                                                         class_mode  = CLASS_MODE,\n",
    "                                                         target_size = TARGET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9470464   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,499,189\n",
      "Trainable params: 9,499,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define NN model\n",
    "\n",
    "# define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(TARGET_SIZE + (CHANNELS,)) ),\n",
    "    keras.layers.MaxPool2D(2, 2),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPool2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit your model\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model.\n",
    "# define callBack to stop learning when accuracy reaches 70%\n",
    "class AccCallBack(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.98):\n",
    "          print(f\"\\nReached 98% accuracy so cancelling training in epoch{epoch}\")\n",
    "          self.model.stop_training = True\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=TRAIN_DATA_SIZE/BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=VAL_DATA_SIZE/BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[AccCallBack()],\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image.\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def read_image(path):\n",
    "    img = image.load_img(path, target_size=TARGET_SIZE)\n",
    "    im = image.img_to_array(img)\n",
    "    im = im.reshape((1,) + im.shape)\n",
    "    return im/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5214882]\n",
      "data/dogs_cats/validation/dogs/dog.2005.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "path = \"data/dogs_cats/validation/dogs/dog.2005.jpg\"\n",
    "img=read_image(path) \n",
    "  \n",
    "classes = model.predict(img, batch_size=10)\n",
    "\n",
    "print(classes[0])\n",
    "print(path + \" is a dog\") if classes[0]>0 else print(path + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Intermediate Representations\n",
    "import random\n",
    "\n",
    "# define new model take the image as input and output the intermediat layers output.\n",
    "layers_outputs = [layer.output for layer in model.layers]\n",
    "layers_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# define the model with the input original model input and the output layers.\n",
    "visualization_model = keras.models.Model(inputs = model.input, outputs = layers_outputs)\n",
    "\n",
    "# feed the visualization model with an image.\n",
    "features_map = visualization_model.predict(img)\n",
    "\n",
    "# display the transformed representation of the input image.\n",
    "for layer_name, feature_map in zip(layers_names, features_map):\n",
    "    if len(feature_map.shape) != 4 : continue   # we care about only the conv layers.\n",
    "    rows, cols, n_features = feature_map.shape[1:]\n",
    "    layout = np.zeros((rows, cols*n_features))\n",
    "    \n",
    "    # for every feature map normalize it.\n",
    "    for i in range(n_features):\n",
    "        # Postprocess the feature to make it visually palatable\n",
    "        feature = feature_map[0, :, :, i]\n",
    "        feature = (feature - feature.mean()) / feature.std()\n",
    "        feature = feature * 64 + 128\n",
    "        feature = np.clip(feature, 0, 255).astype('uint8')\n",
    "        layout[:, i * cols : (i + 1) * cols] = feature\n",
    "        \n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(layout, aspect='auto', cmap='viridis')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b122d47ddb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluating Accuracy and Loss for the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluating Accuracy and Loss for the Model\n",
    "acc      = history.history['accuracy']\n",
    "val_acc  = history.history['val_accuracy']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     acc, label=\"train accuracy\" )\n",
    "plt.plot  ( epochs, val_acc, label=\"test accuracy\" )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.legend()\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot  ( epochs,     loss, label=\"train loss\"  )\n",
    "plt.plot  ( epochs, val_loss, label=\"validation loss\" )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_path = \"models/cat_dogs_classifier_model\"\n",
    "\n",
    "# save as tensorflow savedModel format (.pb, variables, assests)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
